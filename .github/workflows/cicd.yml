# GitHub Actions CI/CD Pipeline for HNC Legal Questionnaire
name: HNC Legal CI/CD Pipeline

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
  release:
    types:
      - published

env:
  REGISTRY: ghcr.io
  IMAGE_NAME_BACKEND: ${{ github.repository }}/backend
  IMAGE_NAME_FRONTEND: ${{ github.repository }}/frontend

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Install backend dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install frontend dependencies
      working-directory: ./frontend
      run: |
        npm ci --legacy-peer-deps

    - name: Run backend tests
      working-directory: ./backend
      env:
        DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379/0
        SECRET_KEY: test-secret-key-for-ci-pipeline
        JWT_SECRET_KEY: test-jwt-secret-key-for-ci-pipeline
      run: |
        python -m pytest tests/ -v --cov=. --cov-report=xml

    - name: Run frontend tests
      working-directory: ./frontend
      run: |
        npm test -- --coverage --watchAll=false

    - name: Upload backend coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        flags: backend
        name: backend-coverage

    - name: Upload frontend coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

    - name: Run backend security scan
      working-directory: ./backend
      run: |
        pip install safety bandit
        safety check
        bandit -r . -f json -o bandit-report.json || true

    - name: Run frontend security scan
      working-directory: ./frontend
      run: |
        npm audit --audit-level=high

  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [test, security-scan]
    if: github.event_name != 'pull_request'
    
    outputs:
      backend-image: ${{ steps.backend-meta.outputs.tags }}
      frontend-image: ${{ steps.frontend-meta.outputs.tags }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract backend metadata
      id: backend-meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_BACKEND }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Extract frontend metadata
      id: frontend-meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_FRONTEND }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push backend image
      uses: docker/build-push-action@v5
      with:
        context: ./backend
        push: true
        tags: ${{ steps.backend-meta.outputs.tags }}
        labels: ${{ steps.backend-meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64

    - name: Build and push frontend image
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        push: true
        tags: ${{ steps.frontend-meta.outputs.tags }}
        labels: ${{ steps.frontend-meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/develop'
    environment:
      name: staging
      url: https://staging.hnc-legal.com

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region us-west-2 --name hnc-legal-staging

    - name: Deploy to staging
      run: |
        # Update image tags in Kubernetes manifests
        sed -i "s|hnc-legal/backend:latest|${{ needs.build.outputs.backend-image }}|g" k8s/deployment.yaml
        sed -i "s|hnc-legal/frontend:latest|${{ needs.build.outputs.frontend-image }}|g" k8s/deployment.yaml
        
        # Apply Kubernetes manifests
        kubectl apply -f k8s/ --namespace=hnc-legal-staging
        
        # Wait for deployment to complete
        kubectl rollout status deployment/backend --namespace=hnc-legal-staging --timeout=300s
        kubectl rollout status deployment/frontend --namespace=hnc-legal-staging --timeout=300s

    - name: Run smoke tests
      run: |
        # Wait for services to be ready
        kubectl wait --for=condition=ready pod -l app=backend --namespace=hnc-legal-staging --timeout=300s
        kubectl wait --for=condition=ready pod -l app=frontend --namespace=hnc-legal-staging --timeout=300s
        
        # Get service URL and run basic health checks
        BACKEND_URL=$(kubectl get service backend-service --namespace=hnc-legal-staging -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        curl -f http://$BACKEND_URL:8000/health || exit 1

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://hnc-legal.com

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}
        aws-region: us-west-2

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region us-west-2 --name hnc-legal-production

    - name: Create backup before deployment
      run: |
        # Create database backup
        kubectl exec -n hnc-legal deployment/postgres -- pg_dump -U hnc_user hnc_legal > backup-$(date +%Y%m%d-%H%M%S).sql
        
        # Upload backup to S3
        aws s3 cp backup-*.sql s3://hnc-legal-backups/pre-deployment/

    - name: Deploy to production
      run: |
        # Update image tags in Kubernetes manifests
        sed -i "s|hnc-legal/backend:latest|${{ needs.build.outputs.backend-image }}|g" k8s/deployment.yaml
        sed -i "s|hnc-legal/frontend:latest|${{ needs.build.outputs.frontend-image }}|g" k8s/deployment.yaml
        
        # Apply Kubernetes manifests with rolling update
        kubectl apply -f k8s/ --namespace=hnc-legal
        
        # Wait for deployment to complete
        kubectl rollout status deployment/backend --namespace=hnc-legal --timeout=600s
        kubectl rollout status deployment/frontend --namespace=hnc-legal --timeout=600s

    - name: Run production health checks
      run: |
        # Wait for services to be ready
        kubectl wait --for=condition=ready pod -l app=backend --namespace=hnc-legal --timeout=300s
        kubectl wait --for=condition=ready pod -l app=frontend --namespace=hnc-legal --timeout=300s
        
        # Run comprehensive health checks
        BACKEND_URL=$(kubectl get service nginx-service --namespace=hnc-legal -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        
        # Test backend health
        curl -f https://$BACKEND_URL/api/health || exit 1
        
        # Test frontend
        curl -f https://$BACKEND_URL/ || exit 1
        
        # Test database connectivity
        kubectl exec -n hnc-legal deployment/backend -- python -c "
        import psycopg2
        import os
        conn = psycopg2.connect(os.environ['DATABASE_URL'])
        cur = conn.cursor()
        cur.execute('SELECT 1')
        assert cur.fetchone()[0] == 1
        print('Database connectivity: OK')
        "

    - name: Notify deployment success
      if: success()
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#deployments'
        message: |
          ✅ HNC Legal Production Deployment Successful
          
          **Commit:** ${{ github.sha }}
          **Author:** ${{ github.actor }}
          **Branch:** ${{ github.ref_name }}
          
          **Images:**
          - Backend: ${{ needs.build.outputs.backend-image }}
          - Frontend: ${{ needs.build.outputs.frontend-image }}
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

    - name: Notify deployment failure
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        channel: '#deployments'
        message: |
          ❌ HNC Legal Production Deployment Failed
          
          **Commit:** ${{ github.sha }}
          **Author:** ${{ github.actor }}
          **Branch:** ${{ github.ref_name }}
          
          Please check the GitHub Actions logs for details.
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  cleanup:
    name: Cleanup Old Images
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always() && (needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success')

    steps:
    - name: Delete old container images
      uses: actions/delete-package-versions@v4
      with:
        package-name: 'backend'
        package-type: 'container'
        min-versions-to-keep: 10
        delete-only-untagged-versions: true

    - name: Delete old frontend images
      uses: actions/delete-package-versions@v4
      with:
        package-name: 'frontend'
        package-type: 'container'
        min-versions-to-keep: 10
        delete-only-untagged-versions: true